{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b0a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from riskfolio import Portfolio\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "import pandas_market_calendars as mcal\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "import scipy.optimize as sco\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import matplotlib.lines as mlinesv\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad39b3",
   "metadata": {},
   "source": [
    "LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6791677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_data(\n",
    "    start_date='2020-01-01',\n",
    "    end_date=datetime.today(),\n",
    "    assets=[\"Stock\", \"Bond\", \"Commodity\", \"forex\"],  # or use \"All\" for everything\n",
    "    path_stock=\"data\\\\master_stock_data.csv\",\n",
    "    path_bond=\"data\\\\master_bond_etf_data.csv\",\n",
    "    path_commodity=\"data\\\\master_commodity_etf_data.csv\",\n",
    "    path_forex=\"data\\\\master_forex_data.csv\"\n",
    "):\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now()\n",
    "\n",
    "    # Convert to Timestamps\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    def load_and_filter(filepath, asset_type):\n",
    "        df = pd.read_csv(filepath, parse_dates=['Date'])\n",
    "        df = df[(df['Date'] > start_date) & (df['Date'] <= end_date)]\n",
    "        df['AssetType'] = asset_type\n",
    "        return df\n",
    "\n",
    "    # Normalize asset input\n",
    "    if isinstance(assets, str):\n",
    "        assets = [assets]\n",
    "    if \"All\" in assets:\n",
    "        assets = [\"Stock\", \"Bond\", \"Commodity\"]\n",
    "\n",
    "    combined = []\n",
    "\n",
    "    if \"Stock\" in assets:\n",
    "        combined.append(load_and_filter(path_stock, \"Stock\"))\n",
    "\n",
    "    if \"Bond\" in assets:\n",
    "        try:\n",
    "            combined.append(load_and_filter(path_bond, \"Bond\"))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {path_bond} not found. Skipping Bond data.\")\n",
    "\n",
    "    if \"Commodity\" in assets:\n",
    "        try:\n",
    "            combined.append(load_and_filter(path_commodity, \"Commodity\"))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {path_commodity} not found. Skipping Commodity data.\")\n",
    "            \n",
    "    if \"forex\" in assets:\n",
    "        try:\n",
    "            combined.append(load_and_filter(path_forex, \"Commodity\"))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {path_forex} not found. Skipping forex data.\")\n",
    "\n",
    "    if not combined:\n",
    "        raise ValueError(\"No valid asset types selected or no files found.\")\n",
    "\n",
    "    final_df = pd.concat(combined, ignore_index=True)\n",
    "    final_df.sort_values(by=\"Date\", inplace=True)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228a2d5",
   "metadata": {},
   "source": [
    "ASSET SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bf20df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_correlation(price_df, corr_threshold=0.3, pairs=False):\n",
    "    df = price_df.copy()\n",
    "    if 'Date' not in df.columns or 'Symbol' not in df.columns or 'Close' not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain 'Date', 'Symbol', and 'Close' columns.\")\n",
    "    \n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date')\n",
    "\n",
    "    returns = df.pivot(index='Date', columns='Symbol', values='Close').pct_change().dropna()\n",
    "    corr_matrix = returns.corr()\n",
    "\n",
    "    if pairs:\n",
    "        selected_pairs = []\n",
    "        for asset1 in corr_matrix.columns:\n",
    "            for asset2 in corr_matrix.columns:\n",
    "                if asset1 != asset2 and corr_matrix.loc[asset1, asset2] <= corr_threshold:\n",
    "                # Avoid duplicates (pairs like (AAPL, MSFT) and (MSFT, AAPL))\n",
    "                    if (asset2, asset1) not in selected_pairs:\n",
    "                        selected_pairs.append((asset1, asset2))\n",
    "                        \n",
    "        selected = [asset for pair in selected_pairs for asset in pair]\n",
    "        selected = list(set(selected))  # Remove duplicates\n",
    "        selected_corr_matrix = corr_matrix.loc[selected, selected]\n",
    "        \n",
    "        return selected_pairs, selected_corr_matrix\n",
    "                    \n",
    "                    \n",
    "    else:\n",
    "        selected = []               \n",
    "        for asset in corr_matrix.columns:\n",
    "            \n",
    "            if all(abs(corr_matrix.loc[asset, other]) < corr_threshold for other in selected):\n",
    "                selected.append(asset)\n",
    "                \n",
    "        selected_corr_matrix = corr_matrix.loc[selected, selected]\n",
    "\n",
    "        return selected, selected_corr_matrix\n",
    "    \n",
    "def cointegration_test(asset1, asset2):\n",
    "    \"\"\"\n",
    "    Perform the Engle-Granger two-step cointegration test.\n",
    "    \n",
    "    1. Regress asset1 on asset2.\n",
    "    2. Test the residuals for stationarity using the ADF test.\n",
    "    \n",
    "    Parameters:\n",
    "    - asset1: Series representing the first asset (price or returns).\n",
    "    - asset2: Series representing the second asset (price or returns).\n",
    "    \n",
    "    Returns:\n",
    "    - p_value: p-value from the ADF test on the residuals (indicating cointegration).\n",
    "    - is_cointegrated: Boolean indicating whether the pair is cointegrated.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Run a linear regression of asset1 on asset2\n",
    "    asset1 = sm.add_constant(asset1)  # Add a constant for the intercept term\n",
    "    model = sm.OLS(asset2, asset1)  # OLS regression model\n",
    "    result = model.fit()  # Fit the model\n",
    "    \n",
    "    # Step 2: Get the residuals (errors from the regression)\n",
    "    residuals = result.resid\n",
    "    \n",
    "    beta = result.params.iloc[1] # Get the slope coefficient (beta)\n",
    "    \n",
    "    # Step 3: Perform the ADF test on the residuals\n",
    "    adf_stat, p_value, _, _, critical_values, _ = adfuller(residuals)\n",
    "    \n",
    "    # Step 4: Cointegration condition - if p-value < 0.05, the pair is cointegrated\n",
    "    is_cointegrated = p_value < 0.05\n",
    "    \n",
    "    return p_value, is_cointegrated, beta\n",
    "\n",
    "def test_cointegration_on_pairs(price_df, selected_pairs):\n",
    "    \"\"\"\n",
    "    Test cointegration for a list of asset pairs and return only the cointegrated pairs.\n",
    "    \n",
    "    Parameters:\n",
    "    - price_df: DataFrame with asset prices ('Date', 'Symbol', 'Close').\n",
    "    - selected_pairs: List of tuples containing asset pairs.\n",
    "    \n",
    "    Returns:\n",
    "    - cointegrated_pairs: List of cointegrated pairs.\n",
    "    \"\"\"\n",
    "    cointegrated_pairs = []\n",
    "    betas = {}\n",
    "\n",
    "    for pair in selected_pairs:\n",
    "        asset1_symbol, asset2_symbol = pair\n",
    "\n",
    "        # Get the price data for the two assets\n",
    "        asset1 = price_df[price_df['Symbol'] == asset1_symbol][['Date', 'Close']]\n",
    "        asset2 = price_df[price_df['Symbol'] == asset2_symbol][['Date', 'Close']]\n",
    "\n",
    "        # Align the assets on the same dates (drop missing values)\n",
    "        combined_data = pd.merge(asset1, asset2, on='Date', suffixes=('_1', '_2')).dropna()\n",
    "        \n",
    "        # Get the aligned price data\n",
    "        asset1_aligned = combined_data['Close_1']\n",
    "        asset2_aligned = combined_data['Close_2']\n",
    "\n",
    "        # Perform the cointegration test\n",
    "        p_value, is_cointegrated, beta = cointegration_test(asset1_aligned, asset2_aligned)\n",
    "\n",
    "        # Only store cointegrated pairs\n",
    "        if is_cointegrated:\n",
    "            cointegrated_pairs.append(pair)\n",
    "            betas[pair] = beta\n",
    "\n",
    "    return cointegrated_pairs, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "753f5f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashy\\AppData\\Local\\Temp\\ipykernel_21460\\3026350881.py:9: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = df.pivot(index='Date', columns='Symbol', values='Close').pct_change().dropna()\n"
     ]
    }
   ],
   "source": [
    "df = load_price_data(end_date='2025-01-01')\n",
    "\n",
    "selected, selected_corr_matrix = filter_by_correlation(df, corr_threshold=-0.3, pairs=True)\n",
    "cointegrated_pairs, betas = test_cointegration_on_pairs(df, selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8132e3",
   "metadata": {},
   "source": [
    "BASE STRATEGY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0403dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals_for_pairs(price_df, pairs, window=20, entry_threshold=2.0, exit_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Generate pair trading signals for multiple asset pairs.\n",
    "\n",
    "    Args:\n",
    "        price_df (pd.DataFrame): Long-format price data with columns ['Date', 'Symbol', 'Close'].\n",
    "        pairs (list of tuples): List of (symbol1, symbol2) pairs.\n",
    "        window (int): Rolling window for z-score.\n",
    "        entry_threshold (float): Z-score entry threshold.\n",
    "        exit_threshold (float): Z-score exit threshold.\n",
    "\n",
    "    Returns:\n",
    "        dict: keys = pair tuple, values = dict with:\n",
    "              - 'signals': pd.Series of signals (1, 0, -1) indexed by Date\n",
    "              - 'spread': pd.Series of spread values indexed by Date\n",
    "              - 'z_score': pd.Series of z-score indexed by Date\n",
    "              - 'beta': float hedge ratio from regression\n",
    "              - 'alpha': float intercept from regression\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for sym1, sym2 in pairs:\n",
    "        # Extract prices for each symbol\n",
    "        prices1 = price_df[price_df['Symbol'] == sym1][['Date', 'Close']].set_index('Date').sort_index()\n",
    "        prices2 = price_df[price_df['Symbol'] == sym2][['Date', 'Close']].set_index('Date').sort_index()\n",
    "\n",
    "        # Align on dates (inner join)\n",
    "        combined = prices1.join(prices2, lsuffix='_1', rsuffix='_2').dropna()\n",
    "\n",
    "        if len(combined) < window:\n",
    "            # Not enough data to compute rolling stats, skip\n",
    "            continue\n",
    "\n",
    "        # Step 1: Compute spread = residuals of regressing sym1 on sym2\n",
    "        X = sm.add_constant(combined['Close_2'])\n",
    "        model = sm.OLS(combined['Close_1'], X).fit()\n",
    "        alpha, beta = model.params\n",
    "\n",
    "        spread = combined['Close_1'] - (alpha + beta * combined['Close_2'])\n",
    "\n",
    "        # Step 2: Generate signals from spread using rolling z-score\n",
    "        rolling_mean = spread.rolling(window=window).mean()\n",
    "        rolling_std = spread.rolling(window=window).std()\n",
    "        z_score = (spread - rolling_mean) / rolling_std\n",
    "\n",
    "        # Initialize signals series\n",
    "        signals = pd.Series(0, index=spread.index)\n",
    "\n",
    "        # Shift z-score by 1 to avoid lookahead\n",
    "        z_score_lagged = z_score.shift(1)\n",
    "\n",
    "        # Entry signals\n",
    "        signals[z_score_lagged > entry_threshold] = -1\n",
    "        signals[z_score_lagged < -entry_threshold] = 1\n",
    "\n",
    "        # Forward fill signals to hold position until exit\n",
    "        signals_ffill = signals.copy()\n",
    "        signals_ffill[signals_ffill == 0] = np.nan\n",
    "        signals_ffill = signals_ffill.ffill().fillna(0)\n",
    "\n",
    "        # Exit signals (also based on lagged z-score)\n",
    "        signals_ffill[(signals_ffill == 1) & (z_score_lagged > -exit_threshold)] = 0\n",
    "        signals_ffill[(signals_ffill == -1) & (z_score_lagged < exit_threshold)] = 0\n",
    "\n",
    "        # Save results\n",
    "        results[(sym1, sym2)] = {\n",
    "            'signals': signals_ffill,\n",
    "            'spread': spread,\n",
    "            'z_score': z_score,\n",
    "            'alpha': alpha,\n",
    "            'beta': beta,\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77f09e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_signals = generate_signals_for_pairs(df, cointegrated_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693597bd",
   "metadata": {},
   "source": [
    "WEIGHTING PORTFOLIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d474ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_pair_trade_capital(total_capital, price1, price2, beta):\n",
    "    \"\"\"\n",
    "    Determine number of shares to long/short for pair trading.\n",
    "\n",
    "    Args:\n",
    "        total_capital (float): Total capital to allocate to the pair.\n",
    "        price1 (float): Price of first asset.\n",
    "        price2 (float): Price of second asset.\n",
    "        beta (float): Hedge ratio (regression coefficient).\n",
    "\n",
    "    Returns:\n",
    "        dict: Number of shares to long/short for sym1 and sym2.\n",
    "    \"\"\"\n",
    "    # Normalize beta in absolute terms\n",
    "    abs_beta = abs(beta)\n",
    "\n",
    "    # Dollar allocation per leg: proportionally divide based on |1| and |Î²|\n",
    "    capital_sym1 = total_capital / (1 + abs_beta)\n",
    "    capital_sym2 = total_capital - capital_sym1\n",
    "\n",
    "    # Shares = capital / price\n",
    "    shares_sym1 = capital_sym1 / price1\n",
    "    shares_sym2 = capital_sym2 / price2\n",
    "\n",
    "    return {\n",
    "        'sym1_shares': shares_sym1,\n",
    "        'sym2_shares': shares_sym2,\n",
    "        'sym1_capital': capital_sym1,\n",
    "        'sym2_capital': capital_sym2,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f8f03",
   "metadata": {},
   "source": [
    "RISK MANAGEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfab085",
   "metadata": {},
   "source": [
    "METRICS LOGGING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16496b9",
   "metadata": {},
   "source": [
    "BACKTESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ccc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_pair_trading_with_capital(price_df, pair_signals_dict, capital_allocations):\n",
    "    price_df = price_df.sort_index()\n",
    "    all_dates = sorted(price_df.index.unique())\n",
    "\n",
    "    portfolio_returns = []\n",
    "    portfolio_dates = []\n",
    "\n",
    "    for i in range(len(all_dates) - 1):\n",
    "        date_t = all_dates[i]\n",
    "        date_t1 = all_dates[i + 1]\n",
    "\n",
    "        daily_return = 0\n",
    "        total_capital = sum(capital_allocations.values())\n",
    "        weighted_return_sum = 0\n",
    "\n",
    "        for (sym1, sym2), data in pair_signals_dict.items():\n",
    "            signals = data['signals']\n",
    "            beta = data['beta']\n",
    "\n",
    "            if date_t not in signals.index:\n",
    "                continue\n",
    "\n",
    "            signal = signals.loc[date_t]\n",
    "            if signal == 0:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                price_t_sym1 = price_df.loc[(date_t, sym1), 'Close']\n",
    "                price_t1_sym1 = price_df.loc[(date_t1, sym1), 'Close']\n",
    "                price_t_sym2 = price_df.loc[(date_t, sym2), 'Close']\n",
    "                price_t1_sym2 = price_df.loc[(date_t1, sym2), 'Close']\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            ret_sym1 = (price_t1_sym1 / price_t_sym1) - 1\n",
    "            ret_sym2 = (price_t1_sym2 / price_t_sym2) - 1\n",
    "\n",
    "            pair_ret = signal * (ret_sym1 - beta * ret_sym2)\n",
    "\n",
    "            # Scale pair return by capital allocated\n",
    "            cap = capital_allocations.get((sym1, sym2), 0)\n",
    "            weighted_return_sum += pair_ret * cap\n",
    "\n",
    "        # Normalize portfolio return by total capital invested\n",
    "        if total_capital > 0:\n",
    "            daily_return = weighted_return_sum / total_capital\n",
    "        else:\n",
    "            daily_return = 0\n",
    "\n",
    "        portfolio_dates.append(date_t1)\n",
    "        portfolio_returns.append(daily_return)\n",
    "\n",
    "    return pd.Series(portfolio_returns, index=portfolio_dates).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c62ecbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = backtest_pair_trading(df, pair_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "433e6288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891d845",
   "metadata": {},
   "source": [
    "OTHER FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b486b28",
   "metadata": {},
   "source": [
    "PORTFOLIO PERFORMANCE TRACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4894cb",
   "metadata": {},
   "source": [
    "PLOTTING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
